<!doctype html>
<html lang="en">

<head>
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<link rel="icon" href="img/logo.png" type="image/png">
	<title>John's Portfolio</title>
	<!-- Bootstrap CSS -->
	<link rel="stylesheet" href="css/bootstrap.css">
	<link rel="stylesheet" href="vendors/linericon/style.css">
	<link rel="stylesheet" href="css/font-awesome.min.css">
	<link rel="stylesheet" href="vendors/owl-carousel/owl.carousel.min.css">
	<link rel="stylesheet" href="css/magnific-popup.css">
	<link rel="stylesheet" href="vendors/nice-select/css/nice-select.css">
	<link rel="stylesheet" href="vendors/animate-css/animate.css">
	<link rel="stylesheet" href="vendors/flaticon/flaticon.css">
	<!-- main css -->
	<link rel="stylesheet" href="css/style.css">
	<!--Clicky Tracking
	<script>var clicky_site_ids = clicky_site_ids || []; clicky_site_ids.push(101212419);</script>
	<script async src="//static.getclicky.com/js"></script-->
</head>

<body>

	<!--================Header Menu Area =================-->
	<header class="header_area">
			<div class="main_menu">
				<nav class="navbar navbar-expand-lg navbar-light">
					<div class="container">
						<!-- Brand and toggle get grouped for better mobile display -->
						<a class="navbar-brand" href="index.html"><img src="img/logo.png" alt=""></a>
						<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
						 aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
						<!-- Collect the nav links, forms, and other content for toggling -->
						<div class="collapse navbar-collapse offset" id="navbarSupportedContent">
							<ul class="nav navbar-nav menu_nav justify-content-end">
								<li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
								<li class="nav-item"><a class="nav-link" href="about-us.html">About</a></li>
								<li class="nav-item active"><a class="nav-link" href="portfolio.html">Portfolio</a></li>
								<li class="nav-item"><a class="nav-link" href="contact.html">Contact</a></li>
								<!--
								<li class="nav-item active submenu dropdown">
									<a class="nav-link" href="portfolio.html">Portfolio</a>
									
									<ul class="dropdown-menu">
										<li class="nav-item"><a class="nav-link" href="portfolio.html">Portfolio</a></li>
										<li class="nav-item"><a class="nav-link" href="portfolio-details.html">Portrfolio Details</a>
									</ul>
								
								</li>
								<li class="nav-item submenu dropdown">
									<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true"
									 aria-expanded="false">Pages</a>
									<ul class="dropdown-menu">
										<li class="nav-item"><a class="nav-link" href="elements.html">Elements</a>
									</ul>
								</li>
								<li class="nav-item submenu dropdown">
									<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true"
									 aria-expanded="false">Blog</a>
									<ul class="dropdown-menu">
										<li class="nav-item"><a class="nav-link" href="blog.html">Blog</a></li>
										<li class="nav-item"><a class="nav-link" href="single-blog.html">Blog Details</a></li>
									</ul>
								</li>
								-->
							</ul>
						</div>
					</div>
				</nav>
			</div>
		</header>
	<!--================Header Menu Area =================-->

	<!--================ Start portfolio Banner Area =================-->
	<section class="banner_area">
		<div class="banner_inner d-flex align-items-center">
			<div class="container">
				<div class="banner_content text-right">
					<h1>Portfolio project</h1>
					<div class="page_link">
						<a href="portfolio.html"> Back to Portfolio</a>
					</div>
				</div>
			</div>
		</div>
	</section>
	<!--================ End Portfolio Banner Area =================-->

	<!--================ Start Portfolio Details Area =================-->
	<section class="portfolio_details_area section_gap">
		<div class="container">
			<div class="portfolio_details_inner">
				<div class="row">
					<div class="col-md-6">
						<div class="left_img"><br /><br />
							<img class="img-fluid" src="img/portfolio/multigesture.png" alt="">
						</div>
					</div>
					<div class="offset-md-1 col-md-5">
						<div class="portfolio_right_text mt-30">
							<h3>Multi-Gestures as VR Shortcuts</h3>
							<p>
								This page describes my summary for all of our project milestones with my partner Yi Li for the 3DUI graduate class at Georgia Tech. 
								It focuses on multi-gesture hand recognition, specifically in the virtual reality space. We explore the potential use cases with 
								regards to 3D user interfaces, and we offer a proposal for developing new graphical interaction techniques based on gesture recognition.
								We utilize the Oculus Quests with the hand-tracking SDK, and we achieved a perfect 100 score for the graduate project!
							</p>
							<ul class="list">
								<!--
								<li><span>Rating</span>: <i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i class="fa fa-star"></i><i
									 class="fa fa-star"></i></li>-->
								<li><span>Client:</span>Georgia Tech Graduate Project & Paper</li>
								<li><span>Website:</span><a href="https://github.com/Johnnyhoboy/VR-Multi-Gesture">Github Repo</a></li>
								<li><span>Paper Link:</span><a href="https://drive.google.com/open?id=1EImCe87ylGvnQG0GV9gK8ztIEcpaiG_afJ5rLFtT570">Graduate Paper</a></li>
								<li><span>Completed:</span>May 1, 2020</li>
							</ul>
							<!--
							<ul class="list social_details">
								<li><a href="#"><i class="fa fa-facebook"></i></a></li>
								<li><a href="#"><i class="fa fa-twitter"></i></a></li>
								<li><a href="#"><i class="fa fa-behance"></i></a></li>
								<li><a href="#"><i class="fa fa-dribbble"></i></a></li>
								<li><a href="#"><i class="fa fa-linkedin"></i></a></li>
							</ul>
							-->
						</div>
					</div>
				</div>
				<div class="row justify-content-center">
					<img class="img" width="800" height="350" src="img/portfolio/dt_dip.png">
				</div>
				<p><b><h3>Background</h3></b></p>
				<p>
					Virtual hand tracking has been a long studied concept in the human-computer interaction area for quite some time now. In the past decade, companies such as Oculus and HTC 
					have released commercial VR headsets that came with hand controllers that acted as basic hand trackers. The actual hand functionality of these controllers were initially 
					limited by only sensing your hand positioning in VR space and if the user was pressing a button or not. There was no tracking of individual fingers or complex gestures. 
					<br /><br />
					Advances in consumer VR technology have evolved into many more accurate forms of hand tracking. These include the Leap Motion tracker, which was an add-on IR camera 
					peripheral that was able to pick up complex hand movements. Valve Index’s VR controllers were released in May 2019 and are designed to enable natural interactions with 
					objects in VR games. Most recently in December 2019, Oculus Quest had become the first inside-out tracking VR system to enable an experimental controller-free hand tracking 
					mode using its built in headset cameras. An image of the headset camera system is shown below:	
					<div class="row justify-content-center">
						<img class="img" width="650" height="400" src="img/portfolio/oculusquest.jpg">
					</div>
					As computers and entertainment systems become more pervasive and ubiquitous in society, facilitating interactions to a point where communication with a computer will be as 
					natural as a human is one of the ultimate goals of HCI. Gestures have long been considered as an interaction technique that can potentially deliver more natural, creative, 
					and intuitive methods for communicating with our computers.
					<br /><br />
					Intuitive interaction techniques are a major aspect of AR and VR applications. This means that a user should be able to manipulate virtual objects without the aware utilization 
					of prior knowledge. However, the use of hand gestures and hand gesture recognition is still a challenging research field in the realm of AR & VR as many techniques have not left 
					research laboratories. One main reason is the need for technical devices that are attached to the user’s hand in order to properly track it. However, with advances in controller-less 
					hand tracking technology such as Leap Motion and Oculus Quest, we are one step closer to developing true intuitive interaction techniques. One particular area we want to explore is 
					multi-gesture recognition for user interaction in 3D VR space. 
				</p>
				<p><b><h3>Goal</h3></b></p>
				<p>
					As mentioned prior, our project is to explore whether or not multi-gestures could be a potential shortcut for user interfaces. We want to experiment on an example such as a 3D paint 
					program similar to Tilt Brush or APainter. In these programs, toggling an option on from a 2D menu floating in front of one controller can prove to be quite a tedious task, 
					especially when you need to position your other controller to act as a mouse pointer. Then, to turn the option off or go into a different tool mode (create, erase, etc.) you usually 
					have to redo the process again. If multi-hand gestures were a shortcut similar to keyboard shortcuts, such as CTRL-C and CTRL-V, we can foresee them being handy shortcuts for such 3D paint programs.
					<br /><br />
					The environment we have developed on will be utilizing the Oculus Quests obtained from class. Due to the nature of the Oculus Hand Tracking SDK, we have setup a Unity 2019 3.8f1 project 
					written in C# that is built on the Android module since the Oculus Quest environment is a mobile platform. We have taken example scenes to recreate a hand tracking scene without the 
					need of controllers. At the time of this writing, Oculus Quest does not support development of both controllers and hands at the same time. This will result in Unity crashes if done so.
	
				</p>
				<p><b><h3>Process</h3></b></p>
				<p>
					We have concluded that pinching gestures would be the easiest to implement and differentiate from. Our decision was influenced by the fact that we mainly wanted to create interesting UI interactions, 
					not particularly creating new custom gestures from scratch. The pinching gestures could be generated by combining boolean values and defined as any individual finger touching the thumb. Thankfully, 
					the SDK provided us with enough functionality to distinguish between which individual finger was touching the thumb at any time. This effectively allowed us eight different pinch gestures, four for each hand. 
					<br /><br />
					We decided that the best way to enter and exit different states was with two handed gestures. Double pinching with specific fingers on both hands would be a very niche multi-gesture command. This would help 
					us reduce the amount of false positives of someone accidentally entering a state with only one handed gestures. We have decided for the purposes of usability that our double pinches would be the same pinching 
					gestures on each individual hand. Both index fingers, middle fingers, ring fingers or pinky fingers touching the thumb at the same time would be examples. By using the exact pinch gesture on both hands, 
					this would also help reduce confusion.
				</p>
				<p>
					Our implementation includes four main pinch modes: <br />
					<ol class="ordered-list">
						<li><span>Double index finger pinch: Rotate/Scale</span></li>
						<li><span>Double middle finger pinch: Create/Erase</span></li>
						<li><span>Double ring finger pinch: Copy/Paste</span></li>
						<li><span>Double pinky finger pinch: Color</span></li>
					</ol> <br />
					<div class="row justify-content-center">
						<video width="1000" height="600" controls>
							<source src="img/portfolio/Mode_Change_Demo.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</div>
					The default mode you start off in is color mode. To enter in different modes you simply do the appropriate double gesture. Note that there is no floating 2D or 3D menu present to enter these modes. 
					The purpose of this project is to explore how we can purely use hand gestures as shortcuts in place. However, there is a UI text field that visibly tells you which mode you are currently in. 
					Note that every pinch mode will have controller-like rays pointing outwards from your hands. This is a common adaptation we implemented from Microsoft’s MixedReality toolkit. In place of controllers, 
					these rays will help with object detection and selection in Unity.
				</p>
				<p><b><h3>Rotate/Scale Mode</h3></b></p>
				<div class="row justify-content-center">
					<video width="1000" height="600" controls>
						<source src="img/portfolio/Rotate_Scale_Demo.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</div>
				<p>
					In this mode you can interact with cubes placed in the scene to rotate or scale them. To do a rotate shortcut command, with either hand ray intersecting a cube, do an index finger 
					pinch and hold it while slowly rotating your hand. When you let go of the index finger pinch, the cube stops rotating. The rotation is linearly based on the position of the hand.
					<br /><br />
					To do a scale up shortcut command, with either hand ray intersecting a cube, do a middle finger pinch and hold it to scale up. To do a scale down shortcut command, do a ring finger pinch and hold 
					it to scale down. When you let go of either finger pinches, the cube stops scaling respectively. The scale will be linearly based on how much you hold down the gestures. 
					<br /><br />
					It is important to note that you can perform and hold the pinching gesture with either hand. You can rotate or scale the cube object entirely using one hard, or alternatively, 
					use your left hand ray to select the cube, then rotate or scale with your right hand doing the gesture. We made the decision to give the user both options as they might be left-handed, right-handed or ambidextrous. 

				</p>
				<p><b><h3>Create/Erase Mode</h3></b></p>
				<div class="row justify-content-center">
					<video width="1000" height="600" controls>
						<source src="img/portfolio/Create_Erase_demo.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</div>
				<p>
					In this mode you are granted the ability to create cubes with your left hand and erase with your right hand. To do a create cube command, use your left hand to do an index finger pinch gesture. 
					A cube will be created in front of your hand direction. You can intersect cubes within each other. 
					<br /><br />
					To do an erase cube command, use your right hand to do a middle finger pinch gesture. If there is a cube intersecting your right hand ray, it will erase it. 
					We decided on giving two different functionalities in this mode to test the ease of both hands. We understand sometimes when we draw or create in these paint programs, we want to quickly erase if we’ve misplaced an object.

				</p>
				<p><b><h3>Copy/Paste Mode</h3></b></p>
				<div class="row justify-content-center">
					<video width="1000" height="600" controls>
						<source src="img/portfolio/Copy_Paste_Demo.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</div>
				<p>
					In this mode you are granted the ability to copy an object that is intersecting with one hand ray, and paste the copied object with the opposite hand ray . To do a copy cube command, 
					simply use one of your hands rays to intersect a cube, that cube will be the one that is copied.  To do a paste cube command, use your opposite hand to do an index finger pinch gesture. 
					This will paste the copied cube in front of the opposite hand. We tried to make this as accurate as we could with the calculations.
					<br /><br />
					This mode was heavily inspired by the classic keyboard shortcut of copy and pasting. We recognized that current VR and AR paint programs did not support this functionality, 
					so we sought an opportunity to implement it as it is a common shortcut that people use. This mode will allow the user to quickly select objects to copy and paste using both hands. 
				</p>
				<p><b><h3>Color Mode</h3></b></p>
				<div class="row justify-content-center">
					<video width="1000" height="600" controls>
						<source src="img/portfolio/Color_Demo.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</div>
				<p>
					The default mode you start off in is color mode. In this mode, you are granted the ability to change the color of a cube that is intersecting with either hand ray. 
					To do a color change command, do pinch gestures with different fingers on either hand. Each pinch gesture will correlate to a different color mapped below: <br />
					<ul class="unordered-list">
						<li><span>Left index finger pinch: Red</span></li>
						<li><span>Left middle finger pinch: Green</span></li>
						<li><span>Left ring finger pinch: Blue</span></li>
						<li><span>Left pinky finger pinch: Yellow</span></li>
						<li><span>Right index finger pinch: Pink</span></li>
						<li><span>Right middle finger pinch: Teal</span></li>
						<li><span>Right ring finger pinch: Purple</span></li>
						<li><span>Right pinky finger pinch: Orange</span></li>
					</ul> <br />
					We wanted to experiment with all eight different gestures in one mode and thought changing color was the most appropriate way to do so. This will allow the user 
					to quickly change the color of the object with the eight main colors of the rainbow. This does not have the accuracy or diversity of a color wheel, but could be 
					useful for applications with a limited range of color options or other similar toggles. 
				</p>
				<p><b><h3>Results</h3></b></p>
				<div class="row justify-content-center">
					<video width="1000" height="600" controls>
						<source src="img/portfolio/Combined_Gestures_Demo.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</div>
				<p>
					You can see a combined demo shown above. This project was a meaningful experience for the both of us. With both of us possessing the background of game development and HCI, we are able to experiment with a 
					new area of 3D user interfaces with gesture recognition. It has allowed us to first hand tinker and gain deeper knowledge within the field of virtual reality. 
					Through the entire implementation process, we are able to understand the back-end architecture for AR and VR Unity applications and the process for the hand 
					tracking system in a mixed reality world. We hope that this paper has inspired people to continue exploring this exciting research field, and we cannot wait 
					to see how future systems will implement hand tracking with user interfaces. 
					<br /><br />
					If you want to read our research paper, click the picture below. Link is provided at the top as well as the Github repo!
					<div class="row justify-content-center">
						<a href="https://drive.google.com/open?id=1EImCe87ylGvnQG0GV9gK8ztIEcpaiG_afJ5rLFtT570">
						<img class="img" width="550" height="700" src="img/portfolio/3DUIPaper.png">
					</a></div>
				</p>
				<div class="text-right">
					<a href="#" class="primary-btn">Back to top</a>
				</div>
			</div>
		</div>
	</section>
	<!--================ Start Portfolio Details Area =================-->

	<!--================Footer Area =================-->
	<footer class="footer_area section_gap">
		<div class="container">
			<div class="row footer_inner justify-content-center">
				<div class="col-lg-6 text-center">
					<aside class="f_widget social_widget">
						<div class="f_logo">
							<img src="img/logo.png" alt="">
						</div>
						<div class="f_title">
							<h4>Connect With Me!</h4>
						</div>
						<ul class="list">
							<li><a href="https://www.linkedin.com/in/johnnyhoboy/"><i class="fa fa-linkedin"></i></a></li>
							<li><a href="https://github.com/Johnnyhoboy"><i class="fa fa-github-alt"></i></a></li>
							<li><a href="https://www.facebook.com/Johnnyhoboy"><i class="fa fa-facebook"></i></a></li>
							<li><a href="https://www.instagram.com/johnnyhoboy/"><i class="fa fa-instagram"></i></a></li>
							<li><a href="https://www.yelp.com/user_details?userid=PSnWyssEJLAWgUJevAAtdQ"><i class = "fa fa-yelp"></i></a></li>

						</ul>
					</aside>
					<div class="copyright">
						<p><!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="fa fa-heart-o" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></p>
					</div>
				</div>
			</div>
		</div>
	</footer>
	<!--================End Footer Area =================-->

	<!-- Optional JavaScript -->
	<!-- jQuery first, then Popper.js, then Bootstrap JS -->
	<script src="js/jquery-3.2.1.min.js"></script>
	<script src="js/popper.js"></script>
	<script src="js/bootstrap.min.js"></script>
	<script src="js/stellar.js"></script>
	<script src="js/jquery.magnific-popup.min.js"></script>
	<script src="vendors/nice-select/js/jquery.nice-select.min.js"></script>
	<script src="vendors/isotope/imagesloaded.pkgd.min.js"></script>
	<script src="vendors/isotope/isotope-min.js"></script>
	<script src="vendors/owl-carousel/owl.carousel.min.js"></script>
	<script src="js/jquery.ajaxchimp.min.js"></script>
	<script src="js/mail-script.js"></script>
	<!--gmaps Js-->
	<script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyCjCGmQ0Uq4exrzdcL6rvxywDDOvfAu6eE"></script>
	<script src="js/gmaps.min.js"></script>
	<script src="js/theme.js"></script>
</body>

</html>